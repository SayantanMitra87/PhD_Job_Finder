{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-scraping for Ph.D. jobs in indeed website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Struggle of recent Ph.Ds to find an appropriate job has been a problem for a while. Firstly, they struggle to identify the transferable skills that they honed for year after year in the lab. Secondly, they fail to identify the wide job market that is waiting outside the lab. Some collegaues do stand-out and they have a pretty clear vision what they want to do in their life with the skills they earned in grad school while some finds it difficult to find the right match of his/her dream job. Here I am trying to build an app where people can put their resume in and the app would tell that person most relevant jobs he/she can apply with their skill sets. \n",
    "\n",
    "This notebook will only cover how I scraped indeed. Atfirst I will show the individual components I scraped and then the whole code for scraping all the relevant information. It took me a long time to scrape all the jobs as many jobs are repeated and building a big dataset was time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial preparation\n",
    "URL = \"https://www.indeed.com/jobs?q=PhD+&l=USA\"\n",
    "# request on the above URL\n",
    "webpage = requests.get(URL)\n",
    "# cleaning\n",
    "clean_page = BeautifulSoup(webpage.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract 4 key information from each job posting: Job Title, Company Name, Location, and Job Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Getting Job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quality Control Chemist', 'Scientist - Immunology', 'GMAT, LSAT, & GRE Instructors & Tutors: $106-$116/hr.', 'Scientist (Monoclonal Lab)', 'Geotechnical Engineer (ML)', \"Director, Master's Entry to Practice Program\", 'PhD Researcher', 'PhD Intern', 'Research Scientist, Virtual Humans (PhD)', 'IMMIGRATION SERVICES OFFICER']\n"
     ]
    }
   ],
   "source": [
    "def get_jobtitle(indeed_page):\n",
    "    job_title = []   \n",
    "    # each job posting is nested in a <div> tag\n",
    "    for div in indeed_page.find_all(name='div', attrs={'class':'title'}):\n",
    "        # job_title under <a> tag\n",
    "        for i in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            job_title.append(i['title'])\n",
    "    return job_title\n",
    "        \n",
    "print(get_jobtitle(clean_page)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Getting Company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Edge Pharma, LLC.', 'Immatics US', 'Manhattan Prep', 'Ansh Labs', 'Shannon & Wilson, Inc.', 'University of South Carolina College of Nursing', 'Kiromic', 'Simon-Kucher & Partners', 'Facebook', 'US Department of Homeland Security']\n"
     ]
    }
   ],
   "source": [
    "def get_companyname(indeed_page):\n",
    "    company_name = []\n",
    "    for div in indeed_page.find_all(name='div', attrs={'class':'row'}):\n",
    "        for company in div.find_all(name=\"span\", attrs={\"class\":\"company\"}):\n",
    "            company_name.append(company.text.strip())\n",
    "    return company_name\n",
    "\n",
    "print(get_companyname(clean_page)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Getting Job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Houston, TX', 'Boston, MA', 'Pittsburgh, PA', 'Holtsville, NY', 'Houston, TX 77046 (Montrose area)', 'Los Angeles, CA', 'United States', 'United States', 'Remote', 'Atlanta, GA 30305 (Buckhead area)']\n"
     ]
    }
   ],
   "source": [
    "def get_location(indeed_page):\n",
    "    location_names = []\n",
    "    for div in indeed_page.find_all(name='div', attrs={'class':'row'}):\n",
    "        for location in div.find_all(name=\"span\", attrs={\"class\":\"location\"}):\n",
    "            location_names.append(location.text)\n",
    "    return location_names\n",
    "\n",
    "print(get_location(clean_page)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Getting Job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Master or PhD in Chemistry or other related field (Preferred). As a Quality Control Chemist, you will be working in close cooperation with the Quality Assurance…', 'PhD in Immunology, Biochemistry, Molecular Biology: Immatics is the globally leading biopharmaceutical company in the development of cancer immunotherpaies…', 'The pay is $106 per hour for all classroom teaching and $116 per hour for private tutoring -- up to four times the industry standard.', 'PhD or Master’s degree in Biology or related area; As a key member of the monoclonal antibody department, this individual will provide critical cell culture,…', 'MS or PhD Degree in Geotechnical Engineering supported by a BS Degree in Engineering. Manage multiple clients, contracts, and projects at the same time.']\n"
     ]
    }
   ],
   "source": [
    "def get_job_description(indeed_page):\n",
    "    description = []\n",
    "    for div in indeed_page.find_all(name='div', attrs={'class':'row'}):\n",
    "        for desc in div.find_all(name=\"div\", attrs={\"class\":\"summary\"}):\n",
    "            description.append(desc.text.strip())\n",
    "    return description\n",
    "\n",
    "print(get_job_description(clean_page)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all these together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 500\n",
    "# Collecting jobs specific to 50 biggest cities in US\n",
    "top_50_cities = ['New+York', 'Los+Angeles', 'Chicago', 'Houston', 'Philadelphia', 'Phoenix', 'San+Antonio', 'San+Diego',\n",
    "                 'Dallas', 'San+Jose', 'Austin', 'Jacksonville', 'San+Francisco', 'Indianapolis', 'Columbus', 'Fort+Worth',\n",
    "                 'Charlotte', 'Seattle', 'Denver', 'El+Paso', 'Detroit', 'Washington+DC', 'Boston', 'Memphis', 'Nashville',\n",
    "                 'Portland', 'Oklahoma+City', 'Las+Vegas', 'Baltimore', 'Louisville', 'Milwaukee', 'Albuquerque',\n",
    "                 'Tucson', 'Fresno', 'Sacramento', 'Kansas+City', 'Long+Beach', 'Mesa', 'Atlanta', 'Colorado+Springs',\n",
    "                 'Virginia+Beach', 'Raleigh', 'Omaha', 'Miami', 'Oakland', 'Minneapolis', 'Tulsa', 'Wichita', 'New+Orleans',\n",
    "                 'Pittsburgh', 'Boulder', 'San+Jose', 'Arlington']\n",
    "cols = ['top50_cities', 'job_title', 'company_name', 'location_name', 'description']\n",
    "\n",
    "# Creating the job database\n",
    "database = []\n",
    "for city in top_50_cities:\n",
    "    #print(city) \n",
    "    for i in range(20000, 21000):\n",
    "        page = requests.get('https://www.indeed.com/jobs?q=phd+&l='+str(city)+'&start='+str(i)) # , verify=False\n",
    "        # Ensuring at least 1 second between page grabs\n",
    "        time.sleep(2)      \n",
    "        job = BeautifulSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "        for div in job.find_all(name=\"div\", attrs={\"class\":\"row\"}): \n",
    "            indeed_phd_job = [] \n",
    "            indeed_phd_job.append(city) \n",
    "            \n",
    "            # Extracting Job_title\n",
    "            for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "                indeed_phd_job.append(a[\"title\"]) \n",
    "                \n",
    "            # Extracting Company_name\n",
    "            for company in div.find_all(name=\"span\", attrs={\"class\":\"company\"}):\n",
    "                indeed_phd_job.append(company.text.strip())\n",
    "                \n",
    "            # Extracting Location_name\n",
    "            c = div.findAll('div', attrs={'class': 'location'})\n",
    "            for span in c:\n",
    "                 indeed_phd_job.append(span.text) \n",
    "                    \n",
    "            # Extracting Job_description\n",
    "            for desc in div.find_all(name=\"div\", attrs={\"class\":\"summary\"}):\n",
    "                indeed_phd_job.append(desc.text.strip())\n",
    "                \n",
    "        # Critical to prevent adding duplicate jop posting\n",
    "        if indeed_phd_job not in database:\n",
    "            database.append(indeed_phd_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(database)\n",
    "df.columns = cols\n",
    "df.to_csv('Final_1.csv', index=False)\n",
    "df.to_excel('Final_1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
